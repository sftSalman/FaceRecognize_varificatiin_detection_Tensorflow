{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_recognize_siamese.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOutGNAMbL4/0+5VVWnQC2K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sftSalman/FaceRecognize_varification_detection_Tensorflow/blob/main/Face_recognize_siamese.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OR5v53F4KaDF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Lambda\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageFont, ImageDraw\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "#import cv2\n",
        "from numpy import genfromtxt\n",
        "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "K.set_image_data_format('channels_first')\n",
        "\n",
        "\n",
        "_FLOATX = 'float32'\n",
        "\n",
        "def variable(value, dtype=_FLOATX, name=None):\n",
        "    v = tf.Variable(np.asarray(value, dtype=dtype), name=name)\n",
        "    _get_session().run(v.initializer)\n",
        "    return v\n",
        "\n",
        "def shape(x):\n",
        "    return x.get_shape()\n",
        "\n",
        "def square(x):\n",
        "    return tf.square(x)\n",
        "\n",
        "def zeros(shape, dtype=_FLOATX, name=None):\n",
        "    return variable(np.zeros(shape), dtype, name)\n",
        "\n",
        "def concatenate(tensors, axis=-1):\n",
        "    if axis < 0:\n",
        "        axis = axis % len(tensors[0].get_shape())\n",
        "    return tf.concat(axis, tensors)\n",
        "\n",
        "def LRN2D(x):\n",
        "    return tf.nn.lrn(x, alpha=1e-4, beta=0.75)\n",
        "\n",
        "def conv2d_bn(x,\n",
        "              layer=None,\n",
        "              cv1_out=None,\n",
        "              cv1_filter=(1, 1),\n",
        "              cv1_strides=(1, 1),\n",
        "              cv2_out=None,\n",
        "              cv2_filter=(3, 3),\n",
        "              cv2_strides=(1, 1),\n",
        "              padding=None):\n",
        "    num = '' if cv2_out == None else '1'\n",
        "    tensor = Conv2D(cv1_out, cv1_filter, strides=cv1_strides, data_format='channels_first', name=layer+'_conv'+num)(x)\n",
        "    tensor = BatchNormalization(axis=1, epsilon=0.00001, name=layer+'_bn'+num)(tensor)\n",
        "    tensor = Activation('relu')(tensor)\n",
        "    if padding == None:\n",
        "        return tensor\n",
        "    tensor = ZeroPadding2D(padding=padding, data_format='channels_first')(tensor)\n",
        "    if cv2_out == None:\n",
        "        return tensor\n",
        "    tensor = Conv2D(cv2_out, cv2_filter, strides=cv2_strides, data_format='channels_first', name=layer+'_conv'+'2')(tensor)\n",
        "    tensor = BatchNormalization(axis=1, epsilon=0.00001, name=layer+'_bn'+'2')(tensor)\n",
        "    tensor = Activation('relu')(tensor)\n",
        "    return tensor\n",
        "\n",
        "WEIGHTS = [\n",
        "  'conv1', 'bn1', 'conv2', 'bn2', 'conv3', 'bn3',\n",
        "  'inception_3a_1x1_conv', 'inception_3a_1x1_bn',\n",
        "  'inception_3a_pool_conv', 'inception_3a_pool_bn',\n",
        "  'inception_3a_5x5_conv1', 'inception_3a_5x5_conv2', 'inception_3a_5x5_bn1', 'inception_3a_5x5_bn2',\n",
        "  'inception_3a_3x3_conv1', 'inception_3a_3x3_conv2', 'inception_3a_3x3_bn1', 'inception_3a_3x3_bn2',\n",
        "  'inception_3b_3x3_conv1', 'inception_3b_3x3_conv2', 'inception_3b_3x3_bn1', 'inception_3b_3x3_bn2',\n",
        "  'inception_3b_5x5_conv1', 'inception_3b_5x5_conv2', 'inception_3b_5x5_bn1', 'inception_3b_5x5_bn2',\n",
        "  'inception_3b_pool_conv', 'inception_3b_pool_bn',\n",
        "  'inception_3b_1x1_conv', 'inception_3b_1x1_bn',\n",
        "  'inception_3c_3x3_conv1', 'inception_3c_3x3_conv2', 'inception_3c_3x3_bn1', 'inception_3c_3x3_bn2',\n",
        "  'inception_3c_5x5_conv1', 'inception_3c_5x5_conv2', 'inception_3c_5x5_bn1', 'inception_3c_5x5_bn2',\n",
        "  'inception_4a_3x3_conv1', 'inception_4a_3x3_conv2', 'inception_4a_3x3_bn1', 'inception_4a_3x3_bn2',\n",
        "  'inception_4a_5x5_conv1', 'inception_4a_5x5_conv2', 'inception_4a_5x5_bn1', 'inception_4a_5x5_bn2',\n",
        "  'inception_4a_pool_conv', 'inception_4a_pool_bn',\n",
        "  'inception_4a_1x1_conv', 'inception_4a_1x1_bn',\n",
        "  'inception_4e_3x3_conv1', 'inception_4e_3x3_conv2', 'inception_4e_3x3_bn1', 'inception_4e_3x3_bn2',\n",
        "  'inception_4e_5x5_conv1', 'inception_4e_5x5_conv2', 'inception_4e_5x5_bn1', 'inception_4e_5x5_bn2',\n",
        "  'inception_5a_3x3_conv1', 'inception_5a_3x3_conv2', 'inception_5a_3x3_bn1', 'inception_5a_3x3_bn2',\n",
        "  'inception_5a_pool_conv', 'inception_5a_pool_bn',\n",
        "  'inception_5a_1x1_conv', 'inception_5a_1x1_bn',\n",
        "  'inception_5b_3x3_conv1', 'inception_5b_3x3_conv2', 'inception_5b_3x3_bn1', 'inception_5b_3x3_bn2',\n",
        "  'inception_5b_pool_conv', 'inception_5b_pool_bn',\n",
        "  'inception_5b_1x1_conv', 'inception_5b_1x1_bn',\n",
        "  'dense_layer'\n",
        "]\n",
        "\n",
        "conv_shape = {\n",
        "  'conv1': [64, 3, 7, 7],\n",
        "  'conv2': [64, 64, 1, 1],\n",
        "  'conv3': [192, 64, 3, 3],\n",
        "  'inception_3a_1x1_conv': [64, 192, 1, 1],\n",
        "  'inception_3a_pool_conv': [32, 192, 1, 1],\n",
        "  'inception_3a_5x5_conv1': [16, 192, 1, 1],\n",
        "  'inception_3a_5x5_conv2': [32, 16, 5, 5],\n",
        "  'inception_3a_3x3_conv1': [96, 192, 1, 1],\n",
        "  'inception_3a_3x3_conv2': [128, 96, 3, 3],\n",
        "  'inception_3b_3x3_conv1': [96, 256, 1, 1],\n",
        "  'inception_3b_3x3_conv2': [128, 96, 3, 3],\n",
        "  'inception_3b_5x5_conv1': [32, 256, 1, 1],\n",
        "  'inception_3b_5x5_conv2': [64, 32, 5, 5],\n",
        "  'inception_3b_pool_conv': [64, 256, 1, 1],\n",
        "  'inception_3b_1x1_conv': [64, 256, 1, 1],\n",
        "  'inception_3c_3x3_conv1': [128, 320, 1, 1],\n",
        "  'inception_3c_3x3_conv2': [256, 128, 3, 3],\n",
        "  'inception_3c_5x5_conv1': [32, 320, 1, 1],\n",
        "  'inception_3c_5x5_conv2': [64, 32, 5, 5],\n",
        "  'inception_4a_3x3_conv1': [96, 640, 1, 1],\n",
        "  'inception_4a_3x3_conv2': [192, 96, 3, 3],\n",
        "  'inception_4a_5x5_conv1': [32, 640, 1, 1,],\n",
        "  'inception_4a_5x5_conv2': [64, 32, 5, 5],\n",
        "  'inception_4a_pool_conv': [128, 640, 1, 1],\n",
        "  'inception_4a_1x1_conv': [256, 640, 1, 1],\n",
        "  'inception_4e_3x3_conv1': [160, 640, 1, 1],\n",
        "  'inception_4e_3x3_conv2': [256, 160, 3, 3],\n",
        "  'inception_4e_5x5_conv1': [64, 640, 1, 1],\n",
        "  'inception_4e_5x5_conv2': [128, 64, 5, 5],\n",
        "  'inception_5a_3x3_conv1': [96, 1024, 1, 1],\n",
        "  'inception_5a_3x3_conv2': [384, 96, 3, 3],\n",
        "  'inception_5a_pool_conv': [96, 1024, 1, 1],\n",
        "  'inception_5a_1x1_conv': [256, 1024, 1, 1],\n",
        "  'inception_5b_3x3_conv1': [96, 736, 1, 1],\n",
        "  'inception_5b_3x3_conv2': [384, 96, 3, 3],\n",
        "  'inception_5b_pool_conv': [96, 736, 1, 1],\n",
        "  'inception_5b_1x1_conv': [256, 736, 1, 1],\n",
        "}\n",
        "\n",
        "def load_weights_from_FaceNet(FRmodel):\n",
        "    # Load weights from csv files (which was exported from Openface torch model)\n",
        "    weights = WEIGHTS\n",
        "    weights_dict = load_weights()\n",
        "\n",
        "    # Set layer weights of the model\n",
        "    for name in weights:\n",
        "        if FRmodel.get_layer(name) != None:\n",
        "            FRmodel.get_layer(name).set_weights(weights_dict[name])\n",
        "        elif model.get_layer(name) != None:\n",
        "            model.get_layer(name).set_weights(weights_dict[name])\n",
        "\n",
        "def load_weights():\n",
        "    # Set weights path\n",
        "    dirPath = './weights'\n",
        "    fileNames = filter(lambda f: not f.startswith('.'), os.listdir(dirPath))\n",
        "    paths = {}\n",
        "    weights_dict = {}\n",
        "\n",
        "    for n in fileNames:\n",
        "        paths[n.replace('.csv', '')] = dirPath + '/' + n\n",
        "\n",
        "    for name in WEIGHTS:\n",
        "        if 'conv' in name:\n",
        "            conv_w = genfromtxt(paths[name + '_w'], delimiter=',', dtype=None)\n",
        "            conv_w = np.reshape(conv_w, conv_shape[name])\n",
        "            conv_w = np.transpose(conv_w, (2, 3, 1, 0))\n",
        "            conv_b = genfromtxt(paths[name + '_b'], delimiter=',', dtype=None)\n",
        "            weights_dict[name] = [conv_w, conv_b]     \n",
        "        elif 'bn' in name:\n",
        "            bn_w = genfromtxt(paths[name + '_w'], delimiter=',', dtype=None)\n",
        "            bn_b = genfromtxt(paths[name + '_b'], delimiter=',', dtype=None)\n",
        "            bn_m = genfromtxt(paths[name + '_m'], delimiter=',', dtype=None)\n",
        "            bn_v = genfromtxt(paths[name + '_v'], delimiter=',', dtype=None)\n",
        "            weights_dict[name] = [bn_w, bn_b, bn_m, bn_v]\n",
        "        elif 'dense' in name:\n",
        "            dense_w = genfromtxt(dirPath+'/dense_w.csv', delimiter=',', dtype=None)\n",
        "            dense_w = np.reshape(dense_w, (128, 736))\n",
        "            dense_w = np.transpose(dense_w, (1, 0))\n",
        "            dense_b = genfromtxt(dirPath+'/dense_b.csv', delimiter=',', dtype=None)\n",
        "            weights_dict[name] = [dense_w, dense_b]\n",
        "\n",
        "    return weights_dict\n",
        "\n",
        "\n",
        "def load_dataset():\n",
        "    train_dataset = h5py.File('datasets/train_happy.h5', \"r\")\n",
        "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
        "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
        "\n",
        "    test_dataset = h5py.File('datasets/test_happy.h5', \"r\")\n",
        "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
        "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
        "\n",
        "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
        "    \n",
        "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
        "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
        "    \n",
        "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
        "\n",
        "def img_to_encoding(image_path, model):\n",
        "    #img = PIL.Image.open(image_path)\n",
        "    img = tf.keras.preprocessing.image.load_img(image_path)\n",
        "    #img = img1[...,::-1]\n",
        "    img = np.around(np.transpose(img, (2,0,1))/255.0, decimals=12)\n",
        "    x_train = np.expand_dims(img, axis=0)\n",
        "    print(x_train.shape)\n",
        "    embedding = model.predict_on_batch(x_train)\n",
        "    return embedding"
      ],
      "metadata": {
        "id": "h1zPysFqHoQd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    BatchNormalization, SeparableConv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\n",
        ")\n",
        "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.layers.core import Lambda, Flatten, Dense\n",
        "from keras.initializers import glorot_uniform\n",
        "#from keras.engine.topology import Layer\n",
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "from keras import backend as K\n",
        "K.set_image_data_format('channels_first')\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "#from fr_utils import *\n",
        "#from inception_blocks_v2 import *\n",
        "\n"
      ],
      "metadata": {
        "id": "jzMfgG32I6on"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from numpy import genfromtxt\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
        "\n",
        "from tensorflow.keras.layers import Lambda, Flatten, Dense\n",
        "\n",
        "K.set_image_data_format('channels_first')\n",
        "\n",
        "def inception_block_1a(X):\n",
        "    \"\"\"\n",
        "    Implementation of an inception block\n",
        "    \"\"\"\n",
        "    \n",
        "    X_3x3 = Conv2D(96, (1, 1), data_format='channels_first', name ='inception_3a_3x3_conv1')(X)\n",
        "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001, name = 'inception_3a_3x3_bn1')(X_3x3)\n",
        "    X_3x3 = Activation('relu')(X_3x3)\n",
        "    X_3x3 = ZeroPadding2D(padding=(1, 1), data_format='channels_first')(X_3x3)\n",
        "    X_3x3 = Conv2D(128, (3, 3), data_format='channels_first', name='inception_3a_3x3_conv2')(X_3x3)\n",
        "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3a_3x3_bn2')(X_3x3)\n",
        "    X_3x3 = Activation('relu')(X_3x3)\n",
        "    \n",
        "    X_5x5 = Conv2D(16, (1, 1), data_format='channels_first', name='inception_3a_5x5_conv1')(X)\n",
        "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3a_5x5_bn1')(X_5x5)\n",
        "    X_5x5 = Activation('relu')(X_5x5)\n",
        "    X_5x5 = ZeroPadding2D(padding=(2, 2), data_format='channels_first')(X_5x5)\n",
        "    X_5x5 = Conv2D(32, (5, 5), data_format='channels_first', name='inception_3a_5x5_conv2')(X_5x5)\n",
        "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3a_5x5_bn2')(X_5x5)\n",
        "    X_5x5 = Activation('relu')(X_5x5)\n",
        "\n",
        "    X_pool = MaxPooling2D(pool_size=3, strides=2, data_format='channels_first')(X)\n",
        "    X_pool = Conv2D(32, (1, 1), data_format='channels_first', name='inception_3a_pool_conv')(X_pool)\n",
        "    X_pool = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3a_pool_bn')(X_pool)\n",
        "    X_pool = Activation('relu')(X_pool)\n",
        "    X_pool = ZeroPadding2D(padding=((3, 4), (3, 4)), data_format='channels_first')(X_pool)\n",
        "\n",
        "    X_1x1 = Conv2D(64, (1, 1), data_format='channels_first', name='inception_3a_1x1_conv')(X)\n",
        "    X_1x1 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3a_1x1_bn')(X_1x1)\n",
        "    X_1x1 = Activation('relu')(X_1x1)\n",
        "        \n",
        "    # CONCAT\n",
        "    inception = concatenate([X_3x3, X_5x5, X_pool, X_1x1], axis=1)\n",
        "\n",
        "    return inception\n",
        "\n",
        "def inception_block_1b(X):\n",
        "    X_3x3 = Conv2D(96, (1, 1), data_format='channels_first', name='inception_3b_3x3_conv1')(X)\n",
        "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_3x3_bn1')(X_3x3)\n",
        "    X_3x3 = Activation('relu')(X_3x3)\n",
        "    X_3x3 = ZeroPadding2D(padding=(1, 1), data_format='channels_first')(X_3x3)\n",
        "    X_3x3 = Conv2D(128, (3, 3), data_format='channels_first', name='inception_3b_3x3_conv2')(X_3x3)\n",
        "    X_3x3 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_3x3_bn2')(X_3x3)\n",
        "    X_3x3 = Activation('relu')(X_3x3)\n",
        "\n",
        "    X_5x5 = Conv2D(32, (1, 1), data_format='channels_first', name='inception_3b_5x5_conv1')(X)\n",
        "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_5x5_bn1')(X_5x5)\n",
        "    X_5x5 = Activation('relu')(X_5x5)\n",
        "    X_5x5 = ZeroPadding2D(padding=(2, 2), data_format='channels_first')(X_5x5)\n",
        "    X_5x5 = Conv2D(64, (5, 5), data_format='channels_first', name='inception_3b_5x5_conv2')(X_5x5)\n",
        "    X_5x5 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_5x5_bn2')(X_5x5)\n",
        "    X_5x5 = Activation('relu')(X_5x5)\n",
        "\n",
        "    X_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3), data_format='channels_first')(X)\n",
        "    X_pool = Conv2D(64, (1, 1), data_format='channels_first', name='inception_3b_pool_conv')(X_pool)\n",
        "    X_pool = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_pool_bn')(X_pool)\n",
        "    X_pool = Activation('relu')(X_pool)\n",
        "    X_pool = ZeroPadding2D(padding=(4, 4), data_format='channels_first')(X_pool)\n",
        "\n",
        "    X_1x1 = Conv2D(64, (1, 1), data_format='channels_first', name='inception_3b_1x1_conv')(X)\n",
        "    X_1x1 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_1x1_bn')(X_1x1)\n",
        "    X_1x1 = Activation('relu')(X_1x1)\n",
        "\n",
        "    inception = concatenate([X_3x3, X_5x5, X_pool, X_1x1], axis=1)\n",
        "\n",
        "    return inception\n",
        "\n",
        "def inception_block_1c(X):\n",
        "    X_3x3 = conv2d_bn(X,\n",
        "                           layer='inception_3c_3x3',\n",
        "                           cv1_out=128,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           cv2_out=256,\n",
        "                           cv2_filter=(3, 3),\n",
        "                           cv2_strides=(2, 2),\n",
        "                           padding=(1, 1))\n",
        "\n",
        "    X_5x5 =conv2d_bn(X,\n",
        "                           layer='inception_3c_5x5',\n",
        "                           cv1_out=32,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           cv2_out=64,\n",
        "                           cv2_filter=(5, 5),\n",
        "                           cv2_strides=(2, 2),\n",
        "                           padding=(2, 2))\n",
        "\n",
        "    X_pool = MaxPooling2D(pool_size=3, strides=2, data_format='channels_first')(X)\n",
        "    X_pool = ZeroPadding2D(padding=((0, 1), (0, 1)), data_format='channels_first')(X_pool)\n",
        "\n",
        "    inception = concatenate([X_3x3, X_5x5, X_pool], axis=1)\n",
        "\n",
        "    return inception\n",
        "\n",
        "def inception_block_2a(X):\n",
        "    X_3x3 = conv2d_bn(X,\n",
        "                           layer='inception_4a_3x3',\n",
        "                           cv1_out=96,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           cv2_out=192,\n",
        "                           cv2_filter=(3, 3),\n",
        "                           cv2_strides=(1, 1),\n",
        "                           padding=(1, 1))\n",
        "    X_5x5 = conv2d_bn(X,\n",
        "                           layer='inception_4a_5x5',\n",
        "                           cv1_out=32,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           cv2_out=64,\n",
        "                           cv2_filter=(5, 5),\n",
        "                           cv2_strides=(1, 1),\n",
        "                           padding=(2, 2))\n",
        "\n",
        "    X_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3), data_format='channels_first')(X)\n",
        "    X_pool = conv2d_bn(X_pool,\n",
        "                           layer='inception_4a_pool',\n",
        "                           cv1_out=128,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           padding=(2, 2))\n",
        "    X_1x1 = conv2d_bn(X,\n",
        "                           layer='inception_4a_1x1',\n",
        "                           cv1_out=256,\n",
        "                           cv1_filter=(1, 1))\n",
        "    inception = concatenate([X_3x3, X_5x5, X_pool, X_1x1], axis=1)\n",
        "\n",
        "    return inception\n",
        "\n",
        "def inception_block_2b(X):\n",
        "    #inception4e\n",
        "    X_3x3 = conv2d_bn(X,\n",
        "                           layer='inception_4e_3x3',\n",
        "                           cv1_out=160,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           cv2_out=256,\n",
        "                           cv2_filter=(3, 3),\n",
        "                           cv2_strides=(2, 2),\n",
        "                           padding=(1, 1))\n",
        "    X_5x5 = conv2d_bn(X,\n",
        "                           layer='inception_4e_5x5',\n",
        "                           cv1_out=64,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           cv2_out=128,\n",
        "                           cv2_filter=(5, 5),\n",
        "                           cv2_strides=(2, 2),\n",
        "                           padding=(2, 2))\n",
        "    \n",
        "    X_pool = MaxPooling2D(pool_size=3, strides=2, data_format='channels_first')(X)\n",
        "    X_pool = ZeroPadding2D(padding=((0, 1), (0, 1)), data_format='channels_first')(X_pool)\n",
        "\n",
        "    inception = concatenate([X_3x3, X_5x5, X_pool], axis=1)\n",
        "\n",
        "    return inception\n",
        "\n",
        "def inception_block_3a(X):\n",
        "    X_3x3 = conv2d_bn(X,\n",
        "                           layer='inception_5a_3x3',\n",
        "                           cv1_out=96,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           cv2_out=384,\n",
        "                           cv2_filter=(3, 3),\n",
        "                           cv2_strides=(1, 1),\n",
        "                           padding=(1, 1))\n",
        "    X_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3), data_format='channels_first')(X)\n",
        "    X_pool = conv2d_bn(X_pool,\n",
        "                           layer='inception_5a_pool',\n",
        "                           cv1_out=96,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           padding=(1, 1))\n",
        "    X_1x1 = conv2d_bn(X,\n",
        "                           layer='inception_5a_1x1',\n",
        "                           cv1_out=256,\n",
        "                           cv1_filter=(1, 1))\n",
        "\n",
        "    inception = concatenate([X_3x3, X_pool, X_1x1], axis=1)\n",
        "\n",
        "    return inception\n",
        "\n",
        "def inception_block_3b(X):\n",
        "    X_3x3 = conv2d_bn(X,\n",
        "                           layer='inception_5b_3x3',\n",
        "                           cv1_out=96,\n",
        "                           cv1_filter=(1, 1),\n",
        "                           cv2_out=384,\n",
        "                           cv2_filter=(3, 3),\n",
        "                           cv2_strides=(1, 1),\n",
        "                           padding=(1, 1))\n",
        "    X_pool = MaxPooling2D(pool_size=3, strides=2, data_format='channels_first')(X)\n",
        "    X_pool = conv2d_bn(X_pool,\n",
        "                           layer='inception_5b_pool',\n",
        "                           cv1_out=96,\n",
        "                           cv1_filter=(1, 1))\n",
        "    X_pool = ZeroPadding2D(padding=(1, 1), data_format='channels_first')(X_pool)\n",
        "\n",
        "    X_1x1 = conv2d_bn(X,\n",
        "                           layer='inception_5b_1x1',\n",
        "                           cv1_out=256,\n",
        "                           cv1_filter=(1, 1))\n",
        "    inception = concatenate([X_3x3, X_pool, X_1x1], axis=1)\n",
        "\n",
        "    return inception\n",
        "\n",
        "def faceRecoModel(input_shape):\n",
        "    \"\"\"\n",
        "    Implementation of the Inception model used for FaceNet\n",
        "    \n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "        \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # First Block\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', data_format='channels_first')(X)\n",
        "    X = BatchNormalization(axis = 1, name = 'bn1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Zero-Padding + MAXPOOL\n",
        "    X = ZeroPadding2D((1, 1),data_format='channels_first' )(X)\n",
        "    X = MaxPooling2D((3, 3), strides = 2, data_format='channels_first')(X)\n",
        "    \n",
        "    # Second Block\n",
        "    X = Conv2D(64, (1, 1), strides = (1, 1), name = 'conv2', data_format='channels_first')(X)\n",
        "    X = BatchNormalization(axis = 1, epsilon=0.00001, name = 'bn2')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Zero-Padding + MAXPOOL\n",
        "    X = ZeroPadding2D((1, 1), data_format='channels_first')(X)\n",
        "\n",
        "    # Second Block\n",
        "    X = Conv2D(192, (3, 3), strides = (1, 1), name = 'conv3', data_format='channels_first')(X)\n",
        "    X = BatchNormalization(axis = 1, epsilon=0.00001, name = 'bn3')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Zero-Padding + MAXPOOL\n",
        "    X = ZeroPadding2D((1, 1), data_format='channels_first')(X)\n",
        "    X = MaxPooling2D(pool_size = 3, strides = 2,data_format='channels_first')(X)\n",
        "    \n",
        "    # Inception 1: a/b/c\n",
        "    X = inception_block_1a(X)\n",
        "    X = inception_block_1b(X)\n",
        "    X = inception_block_1c(X)\n",
        "    \n",
        "    # Inception 2: a/b\n",
        "    X = inception_block_2a(X)\n",
        "    X = inception_block_2b(X)\n",
        "    \n",
        "    # Inception 3: a/b\n",
        "    X = inception_block_3a(X)\n",
        "    X = inception_block_3b(X)\n",
        "    \n",
        "    # Top layer\n",
        "    X = AveragePooling2D(pool_size=(3, 3), strides=(1, 1), data_format='channels_first')(X)\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(128, name='dense_layer')(X)\n",
        "    \n",
        "    # L2 normalization\n",
        "    X = Lambda(lambda  x: K.l2_normalize(x,axis=1))(X)\n",
        "\n",
        "    # Create model instance\n",
        "    model = Model(inputs = X_input, outputs = X, name='FaceRecoModel')\n",
        "        \n",
        "    return model"
      ],
      "metadata": {
        "id": "tKHdbXjGGt-g"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FRmodel = faceRecoModel(input_shape=(3, 96, 96))"
      ],
      "metadata": {
        "id": "00nI5NE6KciB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "\n",
        "json_file = open('/content/model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n"
      ],
      "metadata": {
        "id": "d5odfdIkHNIu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_from_json(loaded_model_json)\n",
        "model.load_weights('/content/model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "ezx-57PDLzAi",
        "outputId": "7538e299-860d-4918-e521-62ec80a96448"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-4dedc66d53fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_model_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[1;32m    425\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[1;32m    426\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n\u001b[0;32m--> 427\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/content/model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    }
  ]
}